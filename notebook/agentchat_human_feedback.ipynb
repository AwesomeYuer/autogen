{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/microsoft/autogen/blob/main/notebook/agentchat_human_feedback.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Auto Generated Agent Chat: Task Solving with Code Generation, Execution, Debugging & Human Feedback\n",
    "\n",
    "AutoGen offers conversable agents powered by LLM, tool, or human, which can be used to perform tasks collectively via automated chat. This framework allows tool use and human participation through multi-agent conversation.\n",
    "Please find documentation about this feature [here](https://microsoft.github.io/autogen/docs/Use-Cases/agent_chat).\n",
    "\n",
    "In this notebook, we demonstrate how to use `AssistantAgent` and `UserProxyAgent` to solve a challenging math problem with human feedback. Here `AssistantAgent` is an LLM-based agent that can write Python code (in a Python coding block) for a user to execute for a given task. `UserProxyAgent` is an agent which serves as a proxy for a user to execute the code written by `AssistantAgent`. By setting `human_input_mode` properly, the `UserProxyAgent` can also prompt the user for feedback to `AssistantAgent`. For example, when `human_input_mode` is set to \"ALWAYS\", the `UserProxyAgent` will always prompt the user for feedback. When user feedback is provided, the `UserProxyAgent` will directly pass the feedback to `AssistantAgent`. When no user feedback is provided, the `UserProxyAgent` will execute the code written by `AssistantAgent` and return the execution results (success or failure and corresponding outputs) to `AssistantAgent`.\n",
    "\n",
    "## Requirements\n",
    "\n",
    "AutoGen requires `Python>=3.8`. To run this notebook example, please install:\n",
    "```bash\n",
    "pip install pyautogen\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-13T23:40:52.317406Z",
     "iopub.status.busy": "2023-02-13T23:40:52.316561Z",
     "iopub.status.idle": "2023-02-13T23:40:52.321193Z",
     "shell.execute_reply": "2023-02-13T23:40:52.320628Z"
    }
   },
   "outputs": [],
   "source": [
    "# %pip install pyautogen~=0.1.0"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set your API Endpoint\n",
    "\n",
    "The [`config_list_from_json`](https://microsoft.github.io/autogen/docs/reference/oai/openai_utils#config_list_from_json) function loads a list of configurations from an environment variable or a json file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import autogen\n",
    "\n",
    "# config_list = autogen.config_list_from_json(\"OAI_CONFIG_LIST\")\n",
    "\n",
    "\n",
    "import autogen\n",
    "\n",
    "config_list = autogen.config_list_from_json(\n",
    "    \"OAI_CONFIG_LIST\",\n",
    "    filter_dict={\n",
    "        # \"model\": [\"gpt-4\", \"gpt-4-0314\", \"gpt4\", \"gpt-4-32k\", \"gpt-4-32k-0314\", \"gpt-4-32k-v0314\"],\n",
    "        \"model\": [\"gpt-35-turbo-16k-dep-001\"]\n",
    "    },\n",
    ")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It first looks for environment variable \"OAI_CONFIG_LIST\" which needs to be a valid json string. If that variable is not found, it then looks for a json file named \"OAI_CONFIG_LIST\".\n",
    "\n",
    "The config list looks like the following:\n",
    "```python\n",
    "config_list = [\n",
    "    {\n",
    "        'model': 'gpt-4',\n",
    "        'api_key': '<your OpenAI API key here>',\n",
    "    },  # OpenAI API endpoint for gpt-4\n",
    "    {\n",
    "        'model': 'gpt-4',\n",
    "        'api_key': '<your first Azure OpenAI API key here>',\n",
    "        'api_base': '<your first Azure OpenAI API base here>',\n",
    "        'api_type': 'azure',\n",
    "        'api_version': '2023-06-01-preview',\n",
    "    },  # Azure OpenAI API endpoint for gpt-4\n",
    "    {\n",
    "        'model': 'gpt-4',\n",
    "        'api_key': '<your second Azure OpenAI API key here>',\n",
    "        'api_base': '<your second Azure OpenAI API base here>',\n",
    "        'api_type': 'azure',\n",
    "        'api_version': '2023-06-01-preview',\n",
    "    },  # another Azure OpenAI API endpoint for gpt-4\n",
    "    {\n",
    "        'model': 'gpt-3.5-turbo',\n",
    "        'api_key': '<your OpenAI API key here>',\n",
    "    },  # OpenAI API endpoint for gpt-3.5-turbo\n",
    "    {\n",
    "        'model': 'gpt-3.5-turbo',\n",
    "        'api_key': '<your first Azure OpenAI API key here>',\n",
    "        'api_base': '<your first Azure OpenAI API base here>',\n",
    "        'api_type': 'azure',\n",
    "        'api_version': '2023-06-01-preview',\n",
    "    },  # Azure OpenAI API endpoint for gpt-3.5-turbo\n",
    "    {\n",
    "        'model': 'gpt-3.5-turbo',\n",
    "        'api_key': '<your second Azure OpenAI API key here>',\n",
    "        'api_base': '<your second Azure OpenAI API base here>',\n",
    "        'api_type': 'azure',\n",
    "        'api_version': '2023-06-01-preview',\n",
    "    },  # another Azure OpenAI API endpoint for gpt-3.5-turbo\n",
    "]\n",
    "```\n",
    "\n",
    "If you open this notebook in colab, you can upload your files by clicking the file icon on the left panel and then choosing \"upload file\" icon.\n",
    "\n",
    "You can set the value of config_list in other ways you prefer, e.g., loading from a YAML file."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct Agents\n",
    "\n",
    "We construct the assistant agent and the user proxy agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an AssistantAgent instance named \"assistant\"\n",
    "assistant = autogen.AssistantAgent(\n",
    "    name=\"assistant\",\n",
    "    llm_config={\n",
    "        \"seed\": 41,\n",
    "        \"config_list\": config_list,\n",
    "    }\n",
    ")\n",
    "# create a UserProxyAgent instance named \"user_proxy\"\n",
    "user_proxy = autogen.UserProxyAgent(\n",
    "    name=\"user_proxy\",\n",
    "    human_input_mode=\"ALWAYS\",\n",
    "    is_termination_msg=lambda x: x.get(\"content\", \"\").rstrip().endswith(\"TERMINATE\"),\n",
    ")\n",
    "\n",
    "# the purpose of the following line is to log the conversation history\n",
    "autogen.ChatCompletion.start_logging()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform a task\n",
    "\n",
    "We invoke the `initiate_chat()` method of the user proxy agent to start the conversation. When you run the cell below, you will be prompted to provide feedback after receiving a message from the assistant agent. If you don't provide any feedback (by pressing Enter directly), the user proxy agent will try to execute the code suggested by the assistant agent on behalf of you, or terminate if the assistant agent sends a \"TERMINATE\" signal at the end of the message."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33muser_proxy\u001b[0m (to assistant):\n",
      "\n",
      "\n",
      "Find $a + b + c$, given that $x+y \\neq -1$ and \n",
      "\\begin{align}\n",
      "\tax + by + c & = x + 7,\\\n",
      "\ta + bx + cy & = 2x + 6y,\\\n",
      "\tay + b + cx & = 4x + y.\n",
      "\\end{align}.\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "[autogen.oai.completion: 10-28 16:48:19] {230} INFO - retrying in 10 seconds...\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/awesomeyuer/miniconda3/envs/autogen-py311-env/lib/python3.11/site-packages/openai/api_requestor.py\", line 606, in request_raw\n",
      "    result = _thread_context.session.request(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/awesomeyuer/miniconda3/envs/autogen-py311-env/lib/python3.11/site-packages/requests/sessions.py\", line 575, in request\n",
      "    prep = self.prepare_request(req)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/awesomeyuer/miniconda3/envs/autogen-py311-env/lib/python3.11/site-packages/requests/sessions.py\", line 486, in prepare_request\n",
      "    p.prepare(\n",
      "  File \"/home/awesomeyuer/miniconda3/envs/autogen-py311-env/lib/python3.11/site-packages/requests/models.py\", line 368, in prepare\n",
      "    self.prepare_url(url, params)\n",
      "  File \"/home/awesomeyuer/miniconda3/envs/autogen-py311-env/lib/python3.11/site-packages/requests/models.py\", line 439, in prepare_url\n",
      "    raise MissingSchema(\n",
      "requests.exceptions.MissingSchema: Invalid URL '<your Azure OpenAI API base here>/openai/deployments/zz-gpt-4/chat/completions?api-version=2023-06-01-preview': No scheme supplied. Perhaps you meant https://<your Azure OpenAI API base here>/openai/deployments/zz-gpt-4/chat/completions?api-version=2023-06-01-preview?\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/awesomeyuer/miniconda3/envs/autogen-py311-env/lib/python3.11/site-packages/autogen/oai/completion.py\", line 224, in _get_response\n",
      "    response = openai_completion.create(request_timeout=request_timeout, **config)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/awesomeyuer/miniconda3/envs/autogen-py311-env/lib/python3.11/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/awesomeyuer/miniconda3/envs/autogen-py311-env/lib/python3.11/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 155, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "                           ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/awesomeyuer/miniconda3/envs/autogen-py311-env/lib/python3.11/site-packages/openai/api_requestor.py\", line 289, in request\n",
      "    result = self.request_raw(\n",
      "             ^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/awesomeyuer/miniconda3/envs/autogen-py311-env/lib/python3.11/site-packages/openai/api_requestor.py\", line 619, in request_raw\n",
      "    raise error.APIConnectionError(\n",
      "openai.error.APIConnectionError: Error communicating with OpenAI: Invalid URL '<your Azure OpenAI API base here>/openai/deployments/zz-gpt-4/chat/completions?api-version=2023-06-01-preview': No scheme supplied. Perhaps you meant https://<your Azure OpenAI API base here>/openai/deployments/zz-gpt-4/chat/completions?api-version=2023-06-01-preview?\n",
      "[autogen.oai.completion: 10-28 16:48:29] {230} INFO - retrying in 10 seconds...\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/awesomeyuer/miniconda3/envs/autogen-py311-env/lib/python3.11/site-packages/openai/api_requestor.py\", line 606, in request_raw\n",
      "    result = _thread_context.session.request(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/awesomeyuer/miniconda3/envs/autogen-py311-env/lib/python3.11/site-packages/requests/sessions.py\", line 575, in request\n",
      "    prep = self.prepare_request(req)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/awesomeyuer/miniconda3/envs/autogen-py311-env/lib/python3.11/site-packages/requests/sessions.py\", line 486, in prepare_request\n",
      "    p.prepare(\n",
      "  File \"/home/awesomeyuer/miniconda3/envs/autogen-py311-env/lib/python3.11/site-packages/requests/models.py\", line 368, in prepare\n",
      "    self.prepare_url(url, params)\n",
      "  File \"/home/awesomeyuer/miniconda3/envs/autogen-py311-env/lib/python3.11/site-packages/requests/models.py\", line 439, in prepare_url\n",
      "    raise MissingSchema(\n",
      "requests.exceptions.MissingSchema: Invalid URL '<your Azure OpenAI API base here>/openai/deployments/zz-gpt-4/chat/completions?api-version=2023-06-01-preview': No scheme supplied. Perhaps you meant https://<your Azure OpenAI API base here>/openai/deployments/zz-gpt-4/chat/completions?api-version=2023-06-01-preview?\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/awesomeyuer/miniconda3/envs/autogen-py311-env/lib/python3.11/site-packages/autogen/oai/completion.py\", line 224, in _get_response\n",
      "    response = openai_completion.create(request_timeout=request_timeout, **config)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/awesomeyuer/miniconda3/envs/autogen-py311-env/lib/python3.11/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/awesomeyuer/miniconda3/envs/autogen-py311-env/lib/python3.11/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 155, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "                           ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/awesomeyuer/miniconda3/envs/autogen-py311-env/lib/python3.11/site-packages/openai/api_requestor.py\", line 289, in request\n",
      "    result = self.request_raw(\n",
      "             ^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/awesomeyuer/miniconda3/envs/autogen-py311-env/lib/python3.11/site-packages/openai/api_requestor.py\", line 619, in request_raw\n",
      "    raise error.APIConnectionError(\n",
      "openai.error.APIConnectionError: Error communicating with OpenAI: Invalid URL '<your Azure OpenAI API base here>/openai/deployments/zz-gpt-4/chat/completions?api-version=2023-06-01-preview': No scheme supplied. Perhaps you meant https://<your Azure OpenAI API base here>/openai/deployments/zz-gpt-4/chat/completions?api-version=2023-06-01-preview?\n",
      "[autogen.oai.completion: 10-28 16:48:39] {230} INFO - retrying in 10 seconds...\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/awesomeyuer/miniconda3/envs/autogen-py311-env/lib/python3.11/site-packages/openai/api_requestor.py\", line 606, in request_raw\n",
      "    result = _thread_context.session.request(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/awesomeyuer/miniconda3/envs/autogen-py311-env/lib/python3.11/site-packages/requests/sessions.py\", line 575, in request\n",
      "    prep = self.prepare_request(req)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/awesomeyuer/miniconda3/envs/autogen-py311-env/lib/python3.11/site-packages/requests/sessions.py\", line 486, in prepare_request\n",
      "    p.prepare(\n",
      "  File \"/home/awesomeyuer/miniconda3/envs/autogen-py311-env/lib/python3.11/site-packages/requests/models.py\", line 368, in prepare\n",
      "    self.prepare_url(url, params)\n",
      "  File \"/home/awesomeyuer/miniconda3/envs/autogen-py311-env/lib/python3.11/site-packages/requests/models.py\", line 439, in prepare_url\n",
      "    raise MissingSchema(\n",
      "requests.exceptions.MissingSchema: Invalid URL '<your Azure OpenAI API base here>/openai/deployments/zz-gpt-4/chat/completions?api-version=2023-06-01-preview': No scheme supplied. Perhaps you meant https://<your Azure OpenAI API base here>/openai/deployments/zz-gpt-4/chat/completions?api-version=2023-06-01-preview?\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/awesomeyuer/miniconda3/envs/autogen-py311-env/lib/python3.11/site-packages/autogen/oai/completion.py\", line 224, in _get_response\n",
      "    response = openai_completion.create(request_timeout=request_timeout, **config)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/awesomeyuer/miniconda3/envs/autogen-py311-env/lib/python3.11/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/awesomeyuer/miniconda3/envs/autogen-py311-env/lib/python3.11/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 155, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "                           ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/awesomeyuer/miniconda3/envs/autogen-py311-env/lib/python3.11/site-packages/openai/api_requestor.py\", line 289, in request\n",
      "    result = self.request_raw(\n",
      "             ^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/awesomeyuer/miniconda3/envs/autogen-py311-env/lib/python3.11/site-packages/openai/api_requestor.py\", line 619, in request_raw\n",
      "    raise error.APIConnectionError(\n",
      "openai.error.APIConnectionError: Error communicating with OpenAI: Invalid URL '<your Azure OpenAI API base here>/openai/deployments/zz-gpt-4/chat/completions?api-version=2023-06-01-preview': No scheme supplied. Perhaps you meant https://<your Azure OpenAI API base here>/openai/deployments/zz-gpt-4/chat/completions?api-version=2023-06-01-preview?\n",
      "[autogen.oai.completion: 10-28 16:48:49] {230} INFO - retrying in 10 seconds...\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/awesomeyuer/miniconda3/envs/autogen-py311-env/lib/python3.11/site-packages/openai/api_requestor.py\", line 606, in request_raw\n",
      "    result = _thread_context.session.request(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/awesomeyuer/miniconda3/envs/autogen-py311-env/lib/python3.11/site-packages/requests/sessions.py\", line 575, in request\n",
      "    prep = self.prepare_request(req)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/awesomeyuer/miniconda3/envs/autogen-py311-env/lib/python3.11/site-packages/requests/sessions.py\", line 486, in prepare_request\n",
      "    p.prepare(\n",
      "  File \"/home/awesomeyuer/miniconda3/envs/autogen-py311-env/lib/python3.11/site-packages/requests/models.py\", line 368, in prepare\n",
      "    self.prepare_url(url, params)\n",
      "  File \"/home/awesomeyuer/miniconda3/envs/autogen-py311-env/lib/python3.11/site-packages/requests/models.py\", line 439, in prepare_url\n",
      "    raise MissingSchema(\n",
      "requests.exceptions.MissingSchema: Invalid URL '<your Azure OpenAI API base here>/openai/deployments/zz-gpt-4/chat/completions?api-version=2023-06-01-preview': No scheme supplied. Perhaps you meant https://<your Azure OpenAI API base here>/openai/deployments/zz-gpt-4/chat/completions?api-version=2023-06-01-preview?\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/awesomeyuer/miniconda3/envs/autogen-py311-env/lib/python3.11/site-packages/autogen/oai/completion.py\", line 224, in _get_response\n",
      "    response = openai_completion.create(request_timeout=request_timeout, **config)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/awesomeyuer/miniconda3/envs/autogen-py311-env/lib/python3.11/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/awesomeyuer/miniconda3/envs/autogen-py311-env/lib/python3.11/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 155, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "                           ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/awesomeyuer/miniconda3/envs/autogen-py311-env/lib/python3.11/site-packages/openai/api_requestor.py\", line 289, in request\n",
      "    result = self.request_raw(\n",
      "             ^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/awesomeyuer/miniconda3/envs/autogen-py311-env/lib/python3.11/site-packages/openai/api_requestor.py\", line 619, in request_raw\n",
      "    raise error.APIConnectionError(\n",
      "openai.error.APIConnectionError: Error communicating with OpenAI: Invalid URL '<your Azure OpenAI API base here>/openai/deployments/zz-gpt-4/chat/completions?api-version=2023-06-01-preview': No scheme supplied. Perhaps you meant https://<your Azure OpenAI API base here>/openai/deployments/zz-gpt-4/chat/completions?api-version=2023-06-01-preview?\n",
      "[autogen.oai.completion: 10-28 16:48:59] {230} INFO - retrying in 10 seconds...\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/awesomeyuer/miniconda3/envs/autogen-py311-env/lib/python3.11/site-packages/openai/api_requestor.py\", line 606, in request_raw\n",
      "    result = _thread_context.session.request(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/awesomeyuer/miniconda3/envs/autogen-py311-env/lib/python3.11/site-packages/requests/sessions.py\", line 575, in request\n",
      "    prep = self.prepare_request(req)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/awesomeyuer/miniconda3/envs/autogen-py311-env/lib/python3.11/site-packages/requests/sessions.py\", line 486, in prepare_request\n",
      "    p.prepare(\n",
      "  File \"/home/awesomeyuer/miniconda3/envs/autogen-py311-env/lib/python3.11/site-packages/requests/models.py\", line 368, in prepare\n",
      "    self.prepare_url(url, params)\n",
      "  File \"/home/awesomeyuer/miniconda3/envs/autogen-py311-env/lib/python3.11/site-packages/requests/models.py\", line 439, in prepare_url\n",
      "    raise MissingSchema(\n",
      "requests.exceptions.MissingSchema: Invalid URL '<your Azure OpenAI API base here>/openai/deployments/zz-gpt-4/chat/completions?api-version=2023-06-01-preview': No scheme supplied. Perhaps you meant https://<your Azure OpenAI API base here>/openai/deployments/zz-gpt-4/chat/completions?api-version=2023-06-01-preview?\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/awesomeyuer/miniconda3/envs/autogen-py311-env/lib/python3.11/site-packages/autogen/oai/completion.py\", line 224, in _get_response\n",
      "    response = openai_completion.create(request_timeout=request_timeout, **config)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/awesomeyuer/miniconda3/envs/autogen-py311-env/lib/python3.11/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/awesomeyuer/miniconda3/envs/autogen-py311-env/lib/python3.11/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 155, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "                           ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/awesomeyuer/miniconda3/envs/autogen-py311-env/lib/python3.11/site-packages/openai/api_requestor.py\", line 289, in request\n",
      "    result = self.request_raw(\n",
      "             ^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/awesomeyuer/miniconda3/envs/autogen-py311-env/lib/python3.11/site-packages/openai/api_requestor.py\", line 619, in request_raw\n",
      "    raise error.APIConnectionError(\n",
      "openai.error.APIConnectionError: Error communicating with OpenAI: Invalid URL '<your Azure OpenAI API base here>/openai/deployments/zz-gpt-4/chat/completions?api-version=2023-06-01-preview': No scheme supplied. Perhaps you meant https://<your Azure OpenAI API base here>/openai/deployments/zz-gpt-4/chat/completions?api-version=2023-06-01-preview?\n",
      "[autogen.oai.completion: 10-28 16:49:09] {230} INFO - retrying in 10 seconds...\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/awesomeyuer/miniconda3/envs/autogen-py311-env/lib/python3.11/site-packages/openai/api_requestor.py\", line 606, in request_raw\n",
      "    result = _thread_context.session.request(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/awesomeyuer/miniconda3/envs/autogen-py311-env/lib/python3.11/site-packages/requests/sessions.py\", line 575, in request\n",
      "    prep = self.prepare_request(req)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/awesomeyuer/miniconda3/envs/autogen-py311-env/lib/python3.11/site-packages/requests/sessions.py\", line 486, in prepare_request\n",
      "    p.prepare(\n",
      "  File \"/home/awesomeyuer/miniconda3/envs/autogen-py311-env/lib/python3.11/site-packages/requests/models.py\", line 368, in prepare\n",
      "    self.prepare_url(url, params)\n",
      "  File \"/home/awesomeyuer/miniconda3/envs/autogen-py311-env/lib/python3.11/site-packages/requests/models.py\", line 439, in prepare_url\n",
      "    raise MissingSchema(\n",
      "requests.exceptions.MissingSchema: Invalid URL '<your Azure OpenAI API base here>/openai/deployments/zz-gpt-4/chat/completions?api-version=2023-06-01-preview': No scheme supplied. Perhaps you meant https://<your Azure OpenAI API base here>/openai/deployments/zz-gpt-4/chat/completions?api-version=2023-06-01-preview?\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/awesomeyuer/miniconda3/envs/autogen-py311-env/lib/python3.11/site-packages/autogen/oai/completion.py\", line 224, in _get_response\n",
      "    response = openai_completion.create(request_timeout=request_timeout, **config)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/awesomeyuer/miniconda3/envs/autogen-py311-env/lib/python3.11/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/awesomeyuer/miniconda3/envs/autogen-py311-env/lib/python3.11/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 155, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "                           ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/awesomeyuer/miniconda3/envs/autogen-py311-env/lib/python3.11/site-packages/openai/api_requestor.py\", line 289, in request\n",
      "    result = self.request_raw(\n",
      "             ^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/awesomeyuer/miniconda3/envs/autogen-py311-env/lib/python3.11/site-packages/openai/api_requestor.py\", line 619, in request_raw\n",
      "    raise error.APIConnectionError(\n",
      "openai.error.APIConnectionError: Error communicating with OpenAI: Invalid URL '<your Azure OpenAI API base here>/openai/deployments/zz-gpt-4/chat/completions?api-version=2023-06-01-preview': No scheme supplied. Perhaps you meant https://<your Azure OpenAI API base here>/openai/deployments/zz-gpt-4/chat/completions?api-version=2023-06-01-preview?\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMissingSchema\u001b[0m                             Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/autogen-py311-env/lib/python3.11/site-packages/openai/api_requestor.py:606\u001b[0m, in \u001b[0;36mAPIRequestor.request_raw\u001b[0;34m(self, method, url, params, supplied_headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[1;32m    605\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 606\u001b[0m     result \u001b[39m=\u001b[39m _thread_context\u001b[39m.\u001b[39;49msession\u001b[39m.\u001b[39;49mrequest(\n\u001b[1;32m    607\u001b[0m         method,\n\u001b[1;32m    608\u001b[0m         abs_url,\n\u001b[1;32m    609\u001b[0m         headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[1;32m    610\u001b[0m         data\u001b[39m=\u001b[39;49mdata,\n\u001b[1;32m    611\u001b[0m         files\u001b[39m=\u001b[39;49mfiles,\n\u001b[1;32m    612\u001b[0m         stream\u001b[39m=\u001b[39;49mstream,\n\u001b[1;32m    613\u001b[0m         timeout\u001b[39m=\u001b[39;49mrequest_timeout \u001b[39mif\u001b[39;49;00m request_timeout \u001b[39melse\u001b[39;49;00m TIMEOUT_SECS,\n\u001b[1;32m    614\u001b[0m         proxies\u001b[39m=\u001b[39;49m_thread_context\u001b[39m.\u001b[39;49msession\u001b[39m.\u001b[39;49mproxies,\n\u001b[1;32m    615\u001b[0m     )\n\u001b[1;32m    616\u001b[0m \u001b[39mexcept\u001b[39;00m requests\u001b[39m.\u001b[39mexceptions\u001b[39m.\u001b[39mTimeout \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/miniconda3/envs/autogen-py311-env/lib/python3.11/site-packages/requests/sessions.py:575\u001b[0m, in \u001b[0;36mSession.request\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    563\u001b[0m req \u001b[39m=\u001b[39m Request(\n\u001b[1;32m    564\u001b[0m     method\u001b[39m=\u001b[39mmethod\u001b[39m.\u001b[39mupper(),\n\u001b[1;32m    565\u001b[0m     url\u001b[39m=\u001b[39murl,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    573\u001b[0m     hooks\u001b[39m=\u001b[39mhooks,\n\u001b[1;32m    574\u001b[0m )\n\u001b[0;32m--> 575\u001b[0m prep \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mprepare_request(req)\n\u001b[1;32m    577\u001b[0m proxies \u001b[39m=\u001b[39m proxies \u001b[39mor\u001b[39;00m {}\n",
      "File \u001b[0;32m~/miniconda3/envs/autogen-py311-env/lib/python3.11/site-packages/requests/sessions.py:486\u001b[0m, in \u001b[0;36mSession.prepare_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    485\u001b[0m p \u001b[39m=\u001b[39m PreparedRequest()\n\u001b[0;32m--> 486\u001b[0m p\u001b[39m.\u001b[39;49mprepare(\n\u001b[1;32m    487\u001b[0m     method\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mmethod\u001b[39m.\u001b[39;49mupper(),\n\u001b[1;32m    488\u001b[0m     url\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49murl,\n\u001b[1;32m    489\u001b[0m     files\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mfiles,\n\u001b[1;32m    490\u001b[0m     data\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mdata,\n\u001b[1;32m    491\u001b[0m     json\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mjson,\n\u001b[1;32m    492\u001b[0m     headers\u001b[39m=\u001b[39;49mmerge_setting(\n\u001b[1;32m    493\u001b[0m         request\u001b[39m.\u001b[39;49mheaders, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mheaders, dict_class\u001b[39m=\u001b[39;49mCaseInsensitiveDict\n\u001b[1;32m    494\u001b[0m     ),\n\u001b[1;32m    495\u001b[0m     params\u001b[39m=\u001b[39;49mmerge_setting(request\u001b[39m.\u001b[39;49mparams, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparams),\n\u001b[1;32m    496\u001b[0m     auth\u001b[39m=\u001b[39;49mmerge_setting(auth, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mauth),\n\u001b[1;32m    497\u001b[0m     cookies\u001b[39m=\u001b[39;49mmerged_cookies,\n\u001b[1;32m    498\u001b[0m     hooks\u001b[39m=\u001b[39;49mmerge_hooks(request\u001b[39m.\u001b[39;49mhooks, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mhooks),\n\u001b[1;32m    499\u001b[0m )\n\u001b[1;32m    500\u001b[0m \u001b[39mreturn\u001b[39;00m p\n",
      "File \u001b[0;32m~/miniconda3/envs/autogen-py311-env/lib/python3.11/site-packages/requests/models.py:368\u001b[0m, in \u001b[0;36mPreparedRequest.prepare\u001b[0;34m(self, method, url, headers, files, data, params, auth, cookies, hooks, json)\u001b[0m\n\u001b[1;32m    367\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprepare_method(method)\n\u001b[0;32m--> 368\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mprepare_url(url, params)\n\u001b[1;32m    369\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprepare_headers(headers)\n",
      "File \u001b[0;32m~/miniconda3/envs/autogen-py311-env/lib/python3.11/site-packages/requests/models.py:439\u001b[0m, in \u001b[0;36mPreparedRequest.prepare_url\u001b[0;34m(self, url, params)\u001b[0m\n\u001b[1;32m    438\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m scheme:\n\u001b[0;32m--> 439\u001b[0m     \u001b[39mraise\u001b[39;00m MissingSchema(\n\u001b[1;32m    440\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mInvalid URL \u001b[39m\u001b[39m{\u001b[39;00murl\u001b[39m!r}\u001b[39;00m\u001b[39m: No scheme supplied. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    441\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mPerhaps you meant https://\u001b[39m\u001b[39m{\u001b[39;00murl\u001b[39m}\u001b[39;00m\u001b[39m?\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    442\u001b[0m     )\n\u001b[1;32m    444\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m host:\n",
      "\u001b[0;31mMissingSchema\u001b[0m: Invalid URL '<your Azure OpenAI API base here>/openai/deployments/zz-gpt-4/chat/completions?api-version=2023-06-01-preview': No scheme supplied. Perhaps you meant https://<your Azure OpenAI API base here>/openai/deployments/zz-gpt-4/chat/completions?api-version=2023-06-01-preview?",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mAPIConnectionError\u001b[0m                        Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/autogen-py311-env/lib/python3.11/site-packages/autogen/oai/completion.py:224\u001b[0m, in \u001b[0;36mCompletion._get_response\u001b[0;34m(cls, config, raise_on_ratelimit_or_timeout, use_cache)\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 224\u001b[0m         response \u001b[39m=\u001b[39m openai_completion\u001b[39m.\u001b[39;49mcreate(request_timeout\u001b[39m=\u001b[39;49mrequest_timeout, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mconfig)\n\u001b[1;32m    225\u001b[0m \u001b[39mexcept\u001b[39;00m (\n\u001b[1;32m    226\u001b[0m     ServiceUnavailableError,\n\u001b[1;32m    227\u001b[0m     APIConnectionError,\n\u001b[1;32m    228\u001b[0m ):\n\u001b[1;32m    229\u001b[0m     \u001b[39m# transient error\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/autogen-py311-env/lib/python3.11/site-packages/openai/api_resources/chat_completion.py:25\u001b[0m, in \u001b[0;36mChatCompletion.create\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 25\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mcreate(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     26\u001b[0m \u001b[39mexcept\u001b[39;00m TryAgain \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/miniconda3/envs/autogen-py311-env/lib/python3.11/site-packages/openai/api_resources/abstract/engine_api_resource.py:155\u001b[0m, in \u001b[0;36mEngineAPIResource.create\u001b[0;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[1;32m    140\u001b[0m (\n\u001b[1;32m    141\u001b[0m     deployment_id,\n\u001b[1;32m    142\u001b[0m     engine,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    152\u001b[0m     api_key, api_base, api_type, api_version, organization, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams\n\u001b[1;32m    153\u001b[0m )\n\u001b[0;32m--> 155\u001b[0m response, _, api_key \u001b[39m=\u001b[39m requestor\u001b[39m.\u001b[39;49mrequest(\n\u001b[1;32m    156\u001b[0m     \u001b[39m\"\u001b[39;49m\u001b[39mpost\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    157\u001b[0m     url,\n\u001b[1;32m    158\u001b[0m     params\u001b[39m=\u001b[39;49mparams,\n\u001b[1;32m    159\u001b[0m     headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[1;32m    160\u001b[0m     stream\u001b[39m=\u001b[39;49mstream,\n\u001b[1;32m    161\u001b[0m     request_id\u001b[39m=\u001b[39;49mrequest_id,\n\u001b[1;32m    162\u001b[0m     request_timeout\u001b[39m=\u001b[39;49mrequest_timeout,\n\u001b[1;32m    163\u001b[0m )\n\u001b[1;32m    165\u001b[0m \u001b[39mif\u001b[39;00m stream:\n\u001b[1;32m    166\u001b[0m     \u001b[39m# must be an iterator\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/autogen-py311-env/lib/python3.11/site-packages/openai/api_requestor.py:289\u001b[0m, in \u001b[0;36mAPIRequestor.request\u001b[0;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrequest\u001b[39m(\n\u001b[1;32m    279\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    280\u001b[0m     method,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    287\u001b[0m     request_timeout: Optional[Union[\u001b[39mfloat\u001b[39m, Tuple[\u001b[39mfloat\u001b[39m, \u001b[39mfloat\u001b[39m]]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    288\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[Union[OpenAIResponse, Iterator[OpenAIResponse]], \u001b[39mbool\u001b[39m, \u001b[39mstr\u001b[39m]:\n\u001b[0;32m--> 289\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrequest_raw(\n\u001b[1;32m    290\u001b[0m         method\u001b[39m.\u001b[39;49mlower(),\n\u001b[1;32m    291\u001b[0m         url,\n\u001b[1;32m    292\u001b[0m         params\u001b[39m=\u001b[39;49mparams,\n\u001b[1;32m    293\u001b[0m         supplied_headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[1;32m    294\u001b[0m         files\u001b[39m=\u001b[39;49mfiles,\n\u001b[1;32m    295\u001b[0m         stream\u001b[39m=\u001b[39;49mstream,\n\u001b[1;32m    296\u001b[0m         request_id\u001b[39m=\u001b[39;49mrequest_id,\n\u001b[1;32m    297\u001b[0m         request_timeout\u001b[39m=\u001b[39;49mrequest_timeout,\n\u001b[1;32m    298\u001b[0m     )\n\u001b[1;32m    299\u001b[0m     resp, got_stream \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_interpret_response(result, stream)\n",
      "File \u001b[0;32m~/miniconda3/envs/autogen-py311-env/lib/python3.11/site-packages/openai/api_requestor.py:619\u001b[0m, in \u001b[0;36mAPIRequestor.request_raw\u001b[0;34m(self, method, url, params, supplied_headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[39mexcept\u001b[39;00m requests\u001b[39m.\u001b[39mexceptions\u001b[39m.\u001b[39mRequestException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m--> 619\u001b[0m     \u001b[39mraise\u001b[39;00m error\u001b[39m.\u001b[39mAPIConnectionError(\n\u001b[1;32m    620\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mError communicating with OpenAI: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(e)\n\u001b[1;32m    621\u001b[0m     ) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n\u001b[1;32m    622\u001b[0m util\u001b[39m.\u001b[39mlog_debug(\n\u001b[1;32m    623\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mOpenAI API response\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    624\u001b[0m     path\u001b[39m=\u001b[39mabs_url,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    627\u001b[0m     request_id\u001b[39m=\u001b[39mresult\u001b[39m.\u001b[39mheaders\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mX-Request-Id\u001b[39m\u001b[39m\"\u001b[39m),\n\u001b[1;32m    628\u001b[0m )\n",
      "\u001b[0;31mAPIConnectionError\u001b[0m: Error communicating with OpenAI: Invalid URL '<your Azure OpenAI API base here>/openai/deployments/zz-gpt-4/chat/completions?api-version=2023-06-01-preview': No scheme supplied. Perhaps you meant https://<your Azure OpenAI API base here>/openai/deployments/zz-gpt-4/chat/completions?api-version=2023-06-01-preview?",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/mnt/d/MyGitHub/autogen/notebook/agentchat_human_feedback.ipynb Cell 10\u001b[0m line \u001b[0;36m1\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04.2-lts-2023-06-27/mnt/d/MyGitHub/autogen/notebook/agentchat_human_feedback.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m math_problem_to_solve \u001b[39m=\u001b[39m \u001b[39m\"\"\"\u001b[39m\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04.2-lts-2023-06-27/mnt/d/MyGitHub/autogen/notebook/agentchat_human_feedback.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mFind $a + b + c$, given that $x+y \u001b[39m\u001b[39m\\\\\u001b[39;00m\u001b[39mneq -1$ and \u001b[39m\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04.2-lts-2023-06-27/mnt/d/MyGitHub/autogen/notebook/agentchat_human_feedback.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39m\\\\\u001b[39;00m\u001b[39mbegin\u001b[39m\u001b[39m{align}\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04.2-lts-2023-06-27/mnt/d/MyGitHub/autogen/notebook/agentchat_human_feedback.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39m\\\\\u001b[39;00m\u001b[39mend\u001b[39m\u001b[39m{align}\u001b[39;00m\u001b[39m.\u001b[39m\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04.2-lts-2023-06-27/mnt/d/MyGitHub/autogen/notebook/agentchat_human_feedback.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39m\"\"\"\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04.2-lts-2023-06-27/mnt/d/MyGitHub/autogen/notebook/agentchat_human_feedback.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39m# the assistant receives a message from the user, which contains the task description\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04.2-lts-2023-06-27/mnt/d/MyGitHub/autogen/notebook/agentchat_human_feedback.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=10'>11</a>\u001b[0m user_proxy\u001b[39m.\u001b[39;49minitiate_chat(assistant, message\u001b[39m=\u001b[39;49mmath_problem_to_solve)\n",
      "File \u001b[0;32m~/miniconda3/envs/autogen-py311-env/lib/python3.11/site-packages/autogen/agentchat/conversable_agent.py:531\u001b[0m, in \u001b[0;36mConversableAgent.initiate_chat\u001b[0;34m(self, recipient, clear_history, silent, **context)\u001b[0m\n\u001b[1;32m    517\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Initiate a chat with the recipient agent.\u001b[39;00m\n\u001b[1;32m    518\u001b[0m \n\u001b[1;32m    519\u001b[0m \u001b[39mReset the consecutive auto reply counter.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    528\u001b[0m \u001b[39m        \"message\" needs to be provided if the `generate_init_message` method is not overridden.\u001b[39;00m\n\u001b[1;32m    529\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    530\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_prepare_chat(recipient, clear_history)\n\u001b[0;32m--> 531\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msend(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgenerate_init_message(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mcontext), recipient, silent\u001b[39m=\u001b[39;49msilent)\n",
      "File \u001b[0;32m~/miniconda3/envs/autogen-py311-env/lib/python3.11/site-packages/autogen/agentchat/conversable_agent.py:334\u001b[0m, in \u001b[0;36mConversableAgent.send\u001b[0;34m(self, message, recipient, request_reply, silent)\u001b[0m\n\u001b[1;32m    332\u001b[0m valid \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_append_oai_message(message, \u001b[39m\"\u001b[39m\u001b[39massistant\u001b[39m\u001b[39m\"\u001b[39m, recipient)\n\u001b[1;32m    333\u001b[0m \u001b[39mif\u001b[39;00m valid:\n\u001b[0;32m--> 334\u001b[0m     recipient\u001b[39m.\u001b[39;49mreceive(message, \u001b[39mself\u001b[39;49m, request_reply, silent)\n\u001b[1;32m    335\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    336\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    337\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mMessage can\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt be converted into a valid ChatCompletion message. Either content or function_call must be provided.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    338\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/autogen-py311-env/lib/python3.11/site-packages/autogen/agentchat/conversable_agent.py:462\u001b[0m, in \u001b[0;36mConversableAgent.receive\u001b[0;34m(self, message, sender, request_reply, silent)\u001b[0m\n\u001b[1;32m    460\u001b[0m \u001b[39mif\u001b[39;00m request_reply \u001b[39mis\u001b[39;00m \u001b[39mFalse\u001b[39;00m \u001b[39mor\u001b[39;00m request_reply \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreply_at_receive[sender] \u001b[39mis\u001b[39;00m \u001b[39mFalse\u001b[39;00m:\n\u001b[1;32m    461\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[0;32m--> 462\u001b[0m reply \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgenerate_reply(messages\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mchat_messages[sender], sender\u001b[39m=\u001b[39;49msender)\n\u001b[1;32m    463\u001b[0m \u001b[39mif\u001b[39;00m reply \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    464\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msend(reply, sender, silent\u001b[39m=\u001b[39msilent)\n",
      "File \u001b[0;32m~/miniconda3/envs/autogen-py311-env/lib/python3.11/site-packages/autogen/agentchat/conversable_agent.py:781\u001b[0m, in \u001b[0;36mConversableAgent.generate_reply\u001b[0;34m(self, messages, sender, exclude)\u001b[0m\n\u001b[1;32m    779\u001b[0m     \u001b[39mcontinue\u001b[39;00m\n\u001b[1;32m    780\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_match_trigger(reply_func_tuple[\u001b[39m\"\u001b[39m\u001b[39mtrigger\u001b[39m\u001b[39m\"\u001b[39m], sender):\n\u001b[0;32m--> 781\u001b[0m     final, reply \u001b[39m=\u001b[39m reply_func(\u001b[39mself\u001b[39;49m, messages\u001b[39m=\u001b[39;49mmessages, sender\u001b[39m=\u001b[39;49msender, config\u001b[39m=\u001b[39;49mreply_func_tuple[\u001b[39m\"\u001b[39;49m\u001b[39mconfig\u001b[39;49m\u001b[39m\"\u001b[39;49m])\n\u001b[1;32m    782\u001b[0m     \u001b[39mif\u001b[39;00m final:\n\u001b[1;32m    783\u001b[0m         \u001b[39mreturn\u001b[39;00m reply\n",
      "File \u001b[0;32m~/miniconda3/envs/autogen-py311-env/lib/python3.11/site-packages/autogen/agentchat/conversable_agent.py:606\u001b[0m, in \u001b[0;36mConversableAgent.generate_oai_reply\u001b[0;34m(self, messages, sender, config)\u001b[0m\n\u001b[1;32m    603\u001b[0m     messages \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_oai_messages[sender]\n\u001b[1;32m    605\u001b[0m \u001b[39m# TODO: #1143 handle token limit exceeded error\u001b[39;00m\n\u001b[0;32m--> 606\u001b[0m response \u001b[39m=\u001b[39m oai\u001b[39m.\u001b[39;49mChatCompletion\u001b[39m.\u001b[39;49mcreate(\n\u001b[1;32m    607\u001b[0m     context\u001b[39m=\u001b[39;49mmessages[\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m]\u001b[39m.\u001b[39;49mpop(\u001b[39m\"\u001b[39;49m\u001b[39mcontext\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m), messages\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_oai_system_message \u001b[39m+\u001b[39;49m messages, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mllm_config\n\u001b[1;32m    608\u001b[0m )\n\u001b[1;32m    609\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mTrue\u001b[39;00m, oai\u001b[39m.\u001b[39mChatCompletion\u001b[39m.\u001b[39mextract_text_or_function_call(response)[\u001b[39m0\u001b[39m]\n",
      "File \u001b[0;32m~/miniconda3/envs/autogen-py311-env/lib/python3.11/site-packages/autogen/oai/completion.py:803\u001b[0m, in \u001b[0;36mCompletion.create\u001b[0;34m(cls, context, use_cache, config_list, filter_func, raise_on_ratelimit_or_timeout, allow_format_str_template, **config)\u001b[0m\n\u001b[1;32m    801\u001b[0m     base_config[\u001b[39m\"\u001b[39m\u001b[39mmax_retry_period\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m    802\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 803\u001b[0m     response \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39;49m\u001b[39m.\u001b[39;49mcreate(\n\u001b[1;32m    804\u001b[0m         context,\n\u001b[1;32m    805\u001b[0m         use_cache,\n\u001b[1;32m    806\u001b[0m         raise_on_ratelimit_or_timeout\u001b[39m=\u001b[39;49mi \u001b[39m<\u001b[39;49m last \u001b[39mor\u001b[39;49;00m raise_on_ratelimit_or_timeout,\n\u001b[1;32m    807\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mbase_config,\n\u001b[1;32m    808\u001b[0m     )\n\u001b[1;32m    809\u001b[0m     \u001b[39mif\u001b[39;00m response \u001b[39m==\u001b[39m \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m:\n\u001b[1;32m    810\u001b[0m         \u001b[39mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m~/miniconda3/envs/autogen-py311-env/lib/python3.11/site-packages/autogen/oai/completion.py:834\u001b[0m, in \u001b[0;36mCompletion.create\u001b[0;34m(cls, context, use_cache, config_list, filter_func, raise_on_ratelimit_or_timeout, allow_format_str_template, **config)\u001b[0m\n\u001b[1;32m    832\u001b[0m \u001b[39mwith\u001b[39;00m diskcache\u001b[39m.\u001b[39mCache(\u001b[39mcls\u001b[39m\u001b[39m.\u001b[39mcache_path) \u001b[39mas\u001b[39;00m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m_cache:\n\u001b[1;32m    833\u001b[0m     \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39mset_cache(seed)\n\u001b[0;32m--> 834\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mcls\u001b[39;49m\u001b[39m.\u001b[39;49m_get_response(params, raise_on_ratelimit_or_timeout\u001b[39m=\u001b[39;49mraise_on_ratelimit_or_timeout)\n",
      "File \u001b[0;32m~/miniconda3/envs/autogen-py311-env/lib/python3.11/site-packages/autogen/oai/completion.py:231\u001b[0m, in \u001b[0;36mCompletion._get_response\u001b[0;34m(cls, config, raise_on_ratelimit_or_timeout, use_cache)\u001b[0m\n\u001b[1;32m    225\u001b[0m \u001b[39mexcept\u001b[39;00m (\n\u001b[1;32m    226\u001b[0m     ServiceUnavailableError,\n\u001b[1;32m    227\u001b[0m     APIConnectionError,\n\u001b[1;32m    228\u001b[0m ):\n\u001b[1;32m    229\u001b[0m     \u001b[39m# transient error\u001b[39;00m\n\u001b[1;32m    230\u001b[0m     logger\u001b[39m.\u001b[39minfo(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mretrying in \u001b[39m\u001b[39m{\u001b[39;00mretry_wait_time\u001b[39m}\u001b[39;00m\u001b[39m seconds...\u001b[39m\u001b[39m\"\u001b[39m, exc_info\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m--> 231\u001b[0m     sleep(retry_wait_time)\n\u001b[1;32m    232\u001b[0m \u001b[39mexcept\u001b[39;00m APIError \u001b[39mas\u001b[39;00m err:\n\u001b[1;32m    233\u001b[0m     error_code \u001b[39m=\u001b[39m err \u001b[39mand\u001b[39;00m err\u001b[39m.\u001b[39mjson_body \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(err\u001b[39m.\u001b[39mjson_body, \u001b[39mdict\u001b[39m) \u001b[39mand\u001b[39;00m err\u001b[39m.\u001b[39mjson_body\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39merror\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "math_problem_to_solve = \"\"\"\n",
    "Find $a + b + c$, given that $x+y \\\\neq -1$ and \n",
    "\\\\begin{align}\n",
    "\tax + by + c & = x + 7,\\\\\n",
    "\ta + bx + cy & = 2x + 6y,\\\\\n",
    "\tay + b + cx & = 4x + y.\n",
    "\\\\end{align}.\n",
    "\"\"\"\n",
    "\n",
    "# the assistant receives a message from the user, which contains the task description\n",
    "user_proxy.initiate_chat(assistant, message=math_problem_to_solve)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze the conversation\n",
    "\n",
    "The human user can provide feedback at each step. When the human user didn't provide feedback, the code was executed. The executed results and error messages are returned to the assistant, and the assistant is able to modify the code based on the feedback. In the end, the task is complete and a \"TERMINATE\" signal is sent from the assistant. The user skipped feedback in the end and the conversation is finished.\n",
    "\n",
    "After the conversation is finished, we can save the conversation log between the two agents. The log can be accessed from `autogen.ChatCompletion.logged_history`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'[{\"content\": \"You are a helpful AI assistant.\\\\nSolve tasks using your coding and language skills.\\\\nIn the following cases, suggest python code (in a python coding block) or shell script (in a sh coding block) for the user to execute.\\\\n    1. When you need to collect info, use the code to output the info you need, for example, browse or search the web, download/read a file, print the content of a webpage or a file, get the current date/time. After sufficient info is printed and the task is ready to be solved based on your language skill, you can solve the task by yourself.\\\\n    2. When you need to perform some task with code, use the code to perform the task and output the result. Finish the task smartly.\\\\nSolve the task step by step if you need to. If a plan is not provided, explain your plan first. Be clear which step uses code, and which step uses your language skill.\\\\nWhen using code, you must indicate the script type in the code block. The user cannot provide any other feedback or perform any other action beyond executing the code you suggest. The user can\\'t modify your code. So do not suggest incomplete code which requires users to modify. Don\\'t use a code block if it\\'s not intended to be executed by the user.\\\\nIf you want the user to save the code in a file before executing it, put # filename: <filename> inside the code block as the first line. Don\\'t include multiple code blocks in one response. Do not ask users to copy and paste the result. Instead, use \\'print\\' function for the output when relevant. Check the execution result returned by the user.\\\\nIf the result indicates there is an error, fix the error and output the code again. Suggest the full code instead of partial code or code changes. If the error can\\'t be fixed or if the task is not solved even after the code is executed successfully, analyze the problem, revisit your assumption, collect additional info you need, and think of a different approach to try.\\\\nWhen you find an answer, verify the answer carefully. Include verifiable evidence in your response if possible.\\\\nReply \\\\\"TERMINATE\\\\\" in the end when everything is done.\\\\n    \", \"role\": \"system\"}, {\"content\": \"\\\\nFind $a + b + c$, given that $x+y \\\\\\\\neq -1$ and \\\\n\\\\\\\\begin{align}\\\\n\\\\tax + by + c & = x + 7,\\\\\\\\\\\\n\\\\ta + bx + cy & = 2x + 6y,\\\\\\\\\\\\n\\\\tay + b + cx & = 4x + y.\\\\n\\\\\\\\end{align}.\\\\n\", \"role\": \"user\"}, {\"content\": \"To solve the system of linear equations, I will use NumPy library in Python to calculate the coefficients and constants and then use the linalg.solve() function to find the values of a, b, and c. Finally, I will add them up to find $a + b + c$.\\\\n\\\\nStep 1: Define the coefficients and constants\\\\n\\\\nStep 2: Solve the system of equations using NumPy\\\\n\\\\nStep 3: Calculate the sum of a, b, and c\", \"role\": \"assistant\"}, {\"content\": \"use sympy\", \"role\": \"user\"}, {\"content\": \"Sure, I will use Sympy to solve the system of linear equations.\\\\n\\\\nStep 1: Import Sympy library and define the symbols\\\\n``` python\\\\nfrom sympy import symbols, Eq, solve\\\\n\\\\na, b, c, x, y = symbols(\\'a b c x y\\')\\\\n```\\\\n\\\\nStep 2: Define the equations\\\\n``` python\\\\neq1 = Eq(a * x + b * y + c, x + 7)\\\\neq2 = Eq(a + b * x + c * y, 2 * x + 6 * y)\\\\neq3 = Eq(a * y + b + c * x, 4 * x + y)\\\\n```\\\\n\\\\nStep 3: Solve the system of equations\\\\n``` python\\\\nsolutions = solve((eq1, eq2, eq3), (a, b, c))\\\\n```\\\\n\\\\nStep 4: Calculate the sum of a, b, and c\\\\n``` python\\\\na_value, b_value, c_value = solutions[a], solutions[b], solutions[c]\\\\nsum_abc = a_value + b_value + c_value\\\\n```\\\\n\\\\n\", \"role\": \"assistant\"}, {\"content\": \"exitcode: 1 (execution failed)\\\\nCode output: \\\\n  File \\\\\"\\\\\", line 2\\\\n    Step 2: Define the equations\\\\n         ^\\\\nSyntaxError: invalid syntax\\\\n\", \"role\": \"user\"}, {\"content\": \"Apologies for the confusion. I should have provided the code in a single block without the step-by-step comments. Here is the code to solve the system of linear equations using Sympy:\\\\n\\\\n```python\\\\nfrom sympy import symbols, Eq, solve\\\\n\\\\na, b, c, x, y = symbols(\\'a b c x y\\')\\\\n\\\\neq1 = Eq(a * x + b * y + c, x + 7)\\\\neq2 = Eq(a + b * x + c * y, 2 * x + 6 * y)\\\\neq3 = Eq(a * y + b + c * x, 4 * x + y)\\\\n\\\\nsolutions = solve((eq1, eq2, eq3), (a, b, c))\\\\n\\\\na_value, b_value, c_value = solutions[a], solutions[b], solutions[c]\\\\nsum_abc = a_value + b_value + c_value\\\\nprint(sum_abc)\\\\n```\\\\n\\\\nPlease run the provided code to find the sum of a, b, and c.\", \"role\": \"assistant\"}, {\"content\": \"exitcode: 0 (execution succeeded)\\\\nCode output: \\\\n(2*x**2 - 3*x + y)/(x**2 - x*y - x + y**2 - y + 1) + (x**2 - 3*x*y + 2*x + y**2 - y)/(x**2 - x*y - x + y**2 - y + 1) + (4*x**2 - 4*x*y - 6*x + 6*y**2 - 7*y + 7)/(x**2 - x*y - x + y**2 - y + 1)\\\\n\", \"role\": \"user\"}, {\"content\": \"I apologize for the confusion. The code provided the sum of a, b, and c in a symbolic representation. To get an answer, we need to put some constraints on x and y for which x + y is not equal to -1.\\\\n\\\\nWe can choose any values for x and y that don\\'t satisfy x + y = -1, and then substitute them into the equation to find the corresponding sum of a, b, and c. Let\\'s use x = 1 and y = 0, which satisfy the given condition.\\\\n\\\\nHere is the updated code with the chosen values for x and y:\\\\n\\\\n```python\\\\nfrom sympy import symbols, Eq, solve\\\\n\\\\na, b, c, x, y = symbols(\\'a b c x y\\')\\\\n\\\\neq1 = Eq(a * x + b * y + c, x + 7)\\\\neq2 = Eq(a + b * x + c * y, 2 * x + 6 * y)\\\\neq3 = Eq(a * y + b + c * x, 4 * x + y)\\\\n\\\\nsolutions = solve((eq1, eq2, eq3), (a, b, c))\\\\n\\\\nchosen_x = 1\\\\nchosen_y = 0\\\\n\\\\na_value, b_value, c_value = solutions[a].subs(x, chosen_x).subs(y, chosen_y), solutions[b].subs(x, chosen_x).subs(y, chosen_y), solutions[c].subs(x, chosen_x).subs(y, chosen_y)\\\\nsum_abc = a_value + b_value + c_value\\\\nprint(sum_abc)\\\\n```\\\\n\\\\nPlease run the provided code again to find the sum of a, b, and c.\", \"role\": \"assistant\"}, {\"content\": \"exitcode: 0 (execution succeeded)\\\\nCode output: \\\\n7\\\\n\", \"role\": \"user\"}, {\"content\": \"Great! Now we have the sum of a, b, and c. The answer is:\\\\n\\\\n$$a + b + c = 7$$\\\\n\\\\nTERMINATE\", \"role\": \"assistant\"}]': {'created_at': [0, 1, 2, 3, 4], 'cost': [0.022019999999999998, 0.03305999999999999, 0.04019999999999999, 0.058589999999999996, 0.050969999999999994]}}\n"
     ]
    }
   ],
   "source": [
    "print(autogen.ChatCompletion.logged_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "json.dump(autogen.ChatCompletion.logged_history, open(\"conversations.json\", \"w\"), indent=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "949777d72b0d2535278d3dc13498b2535136f6dfe0678499012e853ee9abcab1"
   }
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "2d910cfd2d2a4fc49fc30fbbdc5576a7": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "454146d0f7224f038689031002906e6f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_e4ae2b6f5a974fd4bafb6abb9d12ff26",
        "IPY_MODEL_577e1e3cc4db4942b0883577b3b52755",
        "IPY_MODEL_b40bdfb1ac1d4cffb7cefcb870c64d45"
       ],
       "layout": "IPY_MODEL_dc83c7bff2f241309537a8119dfc7555",
       "tabbable": null,
       "tooltip": null
      }
     },
     "577e1e3cc4db4942b0883577b3b52755": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_2d910cfd2d2a4fc49fc30fbbdc5576a7",
       "max": 1,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_74a6ba0c3cbc4051be0a83e152fe1e62",
       "tabbable": null,
       "tooltip": null,
       "value": 1
      }
     },
     "6086462a12d54bafa59d3c4566f06cb2": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "74a6ba0c3cbc4051be0a83e152fe1e62": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "7d3f3d9e15894d05a4d188ff4f466554": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "b40bdfb1ac1d4cffb7cefcb870c64d45": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_f1355871cc6f4dd4b50d9df5af20e5c8",
       "placeholder": "​",
       "style": "IPY_MODEL_ca245376fd9f4354af6b2befe4af4466",
       "tabbable": null,
       "tooltip": null,
       "value": " 1/1 [00:00&lt;00:00, 44.69it/s]"
      }
     },
     "ca245376fd9f4354af6b2befe4af4466": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "dc83c7bff2f241309537a8119dfc7555": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "e4ae2b6f5a974fd4bafb6abb9d12ff26": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_6086462a12d54bafa59d3c4566f06cb2",
       "placeholder": "​",
       "style": "IPY_MODEL_7d3f3d9e15894d05a4d188ff4f466554",
       "tabbable": null,
       "tooltip": null,
       "value": "100%"
      }
     },
     "f1355871cc6f4dd4b50d9df5af20e5c8": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
